
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Core Content 1: Linear Models &#8212; Introduction to Scientific Machine Learning for Engineers</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Core Content 2: Optimization" href="cc-2-optimization.html" />
    <link rel="prev" title="Introduction" href="motivation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Scientific Machine Learning for Engineers</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../about.html">
                    About this Lecture
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preliminaries.html">
   Preliminaries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="motivation.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Core Content 1: Linear Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cc-2-optimization.html">
   Core Content 2: Optimization
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="cc-3-classic-ml.html">
   Core Content 3: Classic ML
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="cc-3-sub-SVM.html">
     Support Vector Machines
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cc-3-sub-GP.html">
     Gaussian Processes
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="cc-4-dl.html">
   Core Content 4: Deep Learning
  </a>
  <input checked class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="cc-4-gradients.html">
     Gradients
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Exercise
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/1_linReg_logReg.html">
   1. Linear Regression and Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/2_BayesianInference.html">
   2. Bayesian Linear and Logistic Regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/3_optimization.html">
   3. Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/4_SVM.html">
   4. Support Vector Machines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../exercise/5_GPs.html">
   5. Gaussian Processes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../admin.html">
   Admin
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../books.html">
   Books
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../preliminary_knowledge.html">
   Preliminary Knowledge
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../faq.html">
   Frequently Asked Questions
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/arturtoshev/SciML22-23"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/arturtoshev/SciML22-23/issues/new?title=Issue%20on%20page%20%2Flecture/cc-1-linear.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lecture/cc-1-linear.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probabilistic-interpretation">
     Probabilistic Interpretation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-logistic-regression">
   Classification &amp; Logistic Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exponential-family">
   Exponential Family
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-inference">
   Bayesian Inference
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#monte-carlo-sampling">
     Monte Carlo Sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#acceptance-rejection-sampling">
       Acceptance-Rejection Sampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sampling-importance-resampling-bayesian-bootstrap">
       Sampling-Importance-Resampling / Bayesian Bootstrap
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adaptive-rejection-sampling">
       Adaptive Rejection Sampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#markov-chain-monte-carlo">
       Markov Chain Monte Carlo
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Bayesian Inference
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-point-estimation">
       Bayesian Point Estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-interval-estimation">
       Bayesian Interval Estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#predictive-distribution-of-a-new-observation">
       Predictive Distribution of a New Observation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-inference-from-a-posterior-random-sample">
       Bayesian Inference from a Posterior Random Sample
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-approaches-to-regression">
   Bayesian Approaches to Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-logistic-regression">
     Bayesian Logistic Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-linear-regression">
     Bayesian Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-machine-learning">
   Bayesian Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-references">
   Further References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Core Content 1: Linear Models</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-regression">
   Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probabilistic-interpretation">
     Probabilistic Interpretation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification-logistic-regression">
   Classification &amp; Logistic Regression
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exponential-family">
   Exponential Family
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-inference">
   Bayesian Inference
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#monte-carlo-sampling">
     Monte Carlo Sampling
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#acceptance-rejection-sampling">
       Acceptance-Rejection Sampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#sampling-importance-resampling-bayesian-bootstrap">
       Sampling-Importance-Resampling / Bayesian Bootstrap
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#adaptive-rejection-sampling">
       Adaptive Rejection Sampling
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#markov-chain-monte-carlo">
       Markov Chain Monte Carlo
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Bayesian Inference
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-point-estimation">
       Bayesian Point Estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-interval-estimation">
       Bayesian Interval Estimation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#predictive-distribution-of-a-new-observation">
       Predictive Distribution of a New Observation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bayesian-inference-from-a-posterior-random-sample">
       Bayesian Inference from a Posterior Random Sample
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-approaches-to-regression">
   Bayesian Approaches to Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-logistic-regression">
     Bayesian Logistic Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bayesian-linear-regression">
     Bayesian Linear Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bayesian-machine-learning">
   Bayesian Machine Learning
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-references">
   Further References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="core-content-1-linear-models">
<h1>Core Content 1: Linear Models<a class="headerlink" href="#core-content-1-linear-models" title="Permalink to this headline">#</a></h1>
<section id="linear-regression">
<h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">#</a></h2>
<p>Linear regression belongs to the family of <strong>supervised learning</strong> approaches, as it inherently requires labeled data. With it being the simplest regression approach. The simplest example to think of would be “Given measurement pairs <span class="math notranslate nohighlight">\(\left\{x^{(i)}, y^{\text {(i)}}\right\}_{i=1,...m}\)</span>, how to fit a line <span class="math notranslate nohighlight">\(h(x)\)</span> to best approximate <span class="math notranslate nohighlight">\(y\)</span>?”</p>
<center><img src = "https://i.imgur.com/kCnveaq.png" width = "350">
<img src = "https://i.imgur.com/pqga0NA.png" width = "350"></center>
<!-- 
x = np.linspace(1.0, 5, N)
X0 = x.reshape(N, 1)
X = np.c_[np.ones((N, 1)), X0]
w = np.array([1., 1 / 9.0])
y = 15 + w[0] * x + w[1] * np.square(x)
y = y + np.random.normal(0, 1, N)  -->
<p>(Source: adapted from <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>)</p>
<p><em>How does it work?</em></p>
<ol>
<li><p>We begin by formulating a hypothesis for the relation between input <span class="math notranslate nohighlight">\(x \in \mathbb{R}^{n}\)</span>, and output <span class="math notranslate nohighlight">\(y \in \mathbb{R}^{p}\)</span>. For conceptual clarity, we will initially set <span class="math notranslate nohighlight">\(p=1\)</span>. Then our hypothesis is represented by</p>
<div class="math notranslate nohighlight">
\[h(x)=\vartheta^{\top} x, \quad h \in \mathbb{R}^{p}\]</div>
<p>as above <span class="math notranslate nohighlight">\(p=1\)</span> in this case, and <span class="math notranslate nohighlight">\(\vartheta \in \mathbb{R}^{n}\)</span> are the parameters of our hypothesis.</p>
</li>
<li><p>Then we need a strategy to fit our hypothesis parameters <span class="math notranslate nohighlight">\(\vartheta\)</span> to the data points we have <span class="math notranslate nohighlight">\(\left\{x^{(i)}, y^{\text {(i)}}\right\}_{i=1,...m}\)</span>.</p>
<ol>
<li><p>Define a suitable cost function <span class="math notranslate nohighlight">\(J\)</span>, which emphasizes the importance of certain traits to the model. I.e. if a certain data area is of special importance to our model we should penalize modeling failures for those points much more heavily than others. A typical choice is the <em>Least Mean Square</em> (LMS) i.e.</p>
<div class="math notranslate nohighlight">
\[J(\vartheta)=\frac{1}{2} \sum_{i=1}^{m}\left(h\left(x^{(i)}\right)-y^{(i)}\right)^{2}\]</div>
</li>
<li><p>Through an iterative application of gradient descent (more on this later in the course) find a <span class="math notranslate nohighlight">\(\vartheta\)</span> which minimizes the cost function <span class="math notranslate nohighlight">\(J(\vartheta)\)</span>. If we apply gradient descent, our update function for the hypothesis parameters then takes the following shape</p></li>
</ol>
<div class="math notranslate nohighlight">
\[\vartheta^{(k+1)}=\vartheta^{(k)}-\alpha\frac{\partial J}{\partial \vartheta^{k}}.\]</div>
</li>
</ol>
<p>The iteration scheme can then be computed as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\frac{\partial J}{\partial \vartheta_{j}}&amp;=\frac{\partial}{\partial \vartheta_{j}} \frac{1}{2} \sum_{i}\left(h\left(x^{(i)}\right)-y^{(i)}\right)^{2} \\
&amp;=\underset{i}{\sum} \frac{\partial }{\partial \vartheta_{j}}\left(h\left(x^{(i)}\right)-y^{(i)}\right)  \\
&amp;=\sum_{i}\left(h\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}.
\end{aligned}
\end{split}\]</div>
<p>resubstituting the iteration scheme into the update function, we then obtain the formula for <strong>batch gradient descent</strong></p>
<div class="math notranslate nohighlight">
\[\vartheta^{(k+1)}_j=\vartheta^{(k)}_j-\alpha\sum_{i}\left(h^{(k)}\left(x^{(i)}\right)-y^{(i)}\right) x_{j}^{(i)}.\]</div>
<p>If we choose an alternative update rate and seek to update every hypothesis parameter individually, then we can apply stochastic gradient descent.</p>
<p>If we now utilize matrix-vector calculus, then we can find the optimal <span class="math notranslate nohighlight">\(\vartheta\)</span> in one shot. To do this we begin by defining our <strong>design matrix <span class="math notranslate nohighlight">\(X\)</span></strong></p>
<div class="math notranslate nohighlight">
\[\begin{split}X_{m \times n}=\left[\begin{array}{c}x^{(1) \top }\\ \vdots \\ x^{(i) \top} \\ \vdots \\ x^{(m) \top}\end{array}\right]\end{split}\]</div>
<p>and then define the feature vector from all samples as</p>
<div class="math notranslate nohighlight">
\[\begin{split}Y_{m \times 1}=\left[\begin{array}{c}y^{(1)} \\ \vdots \\ y^{(i)} \\ \vdots \\ y^{(m)}\end{array}\right]\end{split}\]</div>
<p>Connecting the individual pieces we then get the update function as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\left[\begin{array}{c}
h\left(x^{(0)}\right)-y^{(1)} \\
\vdots \\
h\left(x^{(i)}\right)-y^{(i)} \\
\vdots \\
h\left(x^{(m)}\right)-y^{(m)}
\end{array}\right]=X \vartheta _ {n\times 1} -Y\end{split}\]</div>
<p>According to which, the cost function then becomes</p>
<div class="math notranslate nohighlight">
\[J(\vartheta)=\frac{1}{2}(X \vartheta-Y)^{\top}(X \vartheta-Y).\]</div>
<p>As our cost function <span class="math notranslate nohighlight">\(J(\vartheta)\)</span> is convex, we now only need to check that there exists a minimum i.e.</p>
<div class="math notranslate nohighlight">
\[\nabla_{\vartheta} J(\vartheta) \stackrel{!}{=} 0.\]</div>
<p>Computing the derivative</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\nabla_{\vartheta} J(\vartheta)&amp;=\frac{1}{2} \nabla_{\vartheta}(X \vartheta-Y)^{\top}(X \vartheta-Y) \\
&amp; =\frac{1}{2} \nabla_{\vartheta}(\underbrace{\vartheta^{\top} X^{\top} X \vartheta-\vartheta^{\top} X^{\top} Y-Y^{\top} X \vartheta}_{\text {this is in fact a scalar for $p=1$}}+Y^{\top} Y) \quad \operatorname{as} {\nabla}_{\vartheta} Y^{\top} Y=0 \\
&amp;=\frac{1}{2}\left(2X^{\top} X \vartheta-2 X^{\top} Y\right)
\\
&amp;=X^{\top} X \vartheta-X^{\top} Y \stackrel{!}{=} 0
\end{align}
\end{split}\]</div>
<!-- &=\frac{1}{2} \nabla_{\vartheta} \operatorname{tr}(\cdots) -->
<p>From which follows</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\Rightarrow &amp; \quad X^{\top} X \vartheta=X^{\top} Y
\\
\Rightarrow &amp;\quad\vartheta=\left(X^{\top}X\right)^{-1}X^{\top}Y
\end{align}
\end{split}\]</div>
<p><strong>Exercise: Linear Regression Implementations</strong>
Implement the three approaches (batch gradient descent, stochastic gradient descent, and the matrix approach) to linear regression and compare their performance.</p>
<ol class="simple">
<li><p>Batch Gradient Descent</p></li>
<li><p>Stochastic Gradient Descent</p></li>
<li><p>Matrix Approach</p></li>
</ol>
<section id="probabilistic-interpretation">
<h3>Probabilistic Interpretation<a class="headerlink" href="#probabilistic-interpretation" title="Permalink to this headline">#</a></h3>
<p>With much data in practice, having errors over the collected data itself, we want to be able to include a data error in our linear regression. The approach for this is <strong>Maximum Likelihood Estimation</strong> as introduced in the <em>Introduction</em> lecture. I.e. this means data points are modeled as</p>
<!-- _{\uparrow} -->
<div class="math notranslate nohighlight">
\[y^{(i)}=\vartheta^{\top} x^{(i)}+\varepsilon^{(i)}\]</div>
<p>Presuming that all our data points are <strong>independent, identically distributed (i.i.d)</strong> random variables. The noise is modeled with a normal distribution.</p>
<div class="math notranslate nohighlight">
\[p\left(\varepsilon^{(i)}\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\varepsilon^{(i) 2}}{2 \sigma^{2}}}\]</div>
<blockquote>
<div><p>While most noise distributions in practice are not normal, the normal (a.k.a. Gaussian) distribution has many nice theoretical properties making it much friendlier for theoretical derivations.</p>
</div></blockquote>
<p>Using the data error assumption, we can now derive the probability density function (pdf) for the data</p>
<div class="math notranslate nohighlight">
\[p\left(y^{(i)} \mid x^{(i)} ; \vartheta\right)=\frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}}{2\sigma^{2}}}\]</div>
<p>where <span class="math notranslate nohighlight">\(y^{(i)}\)</span> is conditioned on <span class="math notranslate nohighlight">\(x^{(i)}\)</span>. If we now consider not just the individual sample <span class="math notranslate nohighlight">\(i\)</span>, but the entire dataset, we can define the likelihood for our hypothesis parameters as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
L(\vartheta) &amp;=p(Y \mid X ; \vartheta)=\prod_{i=1}^{m} p\left(y^{(i)} \mid x^{(i)} ; \vartheta\right)
\\
&amp;=\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(y^{(i)}-\vartheta^{T} x^{(i)}\right)^{2}}{2 \sigma^{2}}}
\end{align}
\end{split}\]</div>
<p>The probabilistic strategy to determine the optimal hypothesis parameters <span class="math notranslate nohighlight">\(\vartheta\)</span> is then the maximum likelihood approach for which we resort to the <strong>log-likelihood</strong> as it is monotonically increasing, and easier to optimize for.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
l(\vartheta)&amp;=\log L(\vartheta)=\log \prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{\frac{\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}}{2 \sigma^{2}}}\\
&amp;=\sum_{i=1}^{m} \log \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{ \frac{\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}}{2 \sigma^{2}}}\\
&amp;=m \log \frac{1}{\sqrt{2 \pi \sigma^{2}}}-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{m}\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}\\
&amp;\Rightarrow \vartheta=\operatorname{argmax} l(\vartheta)=\operatorname{argmin} \sum_{i=1}^{m}\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}\\
\end{aligned}
\end{split}\]</div>
<p><strong>This is the same result as minimizing <span class="math notranslate nohighlight">\(J(\vartheta)\)</span> from before.</strong> Interestingly enough, the Gaussian i.i.d. noise used in the maximum likelihood approach is entirely independent of <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>.</p>
<blockquote>
<div><p>Least squares method (LMS), as well as maximum likelihood regression as above are <strong>parametric learning</strong> algorithms.</p>
</div></blockquote>
<blockquote>
<div><p>If the number of parameters is <strong>not</strong> known beforehand, then the algorithms become <strong>non-parametric</strong> learning algorithms.</p>
</div></blockquote>
<p>Can maximum likelihood estimation (MLE) be made more non-parametric? Following intuition the linear MLE, as well as the LMS critically depends on the selection of the features, i.e the dimension of the parameter vector <span class="math notranslate nohighlight">\(\vartheta\)</span>. I.e. when the dimension of <span class="math notranslate nohighlight">\(\vartheta\)</span> is too low we tend to underfit, where we do not capture some of the structure of our data. An approach to cope with the problem of underfitting here is to give more weight to new, unseen data <span class="math notranslate nohighlight">\(x\)</span>. E.g. for x, where we want to estimate y:</p>
<div class="math notranslate nohighlight">
\[\hat{\delta}=\operatorname{argmax} \sum_{i=1}^{m} w^{(i)}\left(y^{(i)}-\vartheta^{\top} x^{(i)}\right)^{2}\]</div>
<p>where <span class="math notranslate nohighlight">\(\omega\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\omega^{(i)}=e^{-\frac{\left(x^{(i)}-x\right)^{2}}{2 \tau^{2}}}.\]</div>
<p>This approach naturally gives more weight to new datapoints in <span class="math notranslate nohighlight">\(x\)</span>. Hence making <span class="math notranslate nohighlight">\(\vartheta\)</span> crucially depend on <span class="math notranslate nohighlight">\(x\)</span>, and making it more non-parametric.</p>
</section>
</section>
<section id="classification-logistic-regression">
<h2>Classification &amp; Logistic Regression<a class="headerlink" href="#classification-logistic-regression" title="Permalink to this headline">#</a></h2>
<p>Summarizing the differences between regression and classification:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>Regression</p></th>
<th class="head"><p>Classification</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(x \in \mathbb{R}^{n}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(x \in \mathbb{R}^{n}\)</span></p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(y \in \mathbb{R}\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(y \in\{0,1\}\)</span></p></td>
</tr>
</tbody>
</table>
<div style="text-align:center">
    <img src="https://i.imgur.com/ZIb72vK.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://github.com/probml/pyprobml/blob/master/notebooks/book1/02/iris_logreg.ipynb">Murphy</a>)</p>
<p>To achieve such classification ability we have to introduce a new hypothesis function <span class="math notranslate nohighlight">\(h(x)\)</span>. A reasonable choice would be to model the probability that <span class="math notranslate nohighlight">\(y=1\)</span> given <span class="math notranslate nohighlight">\(x\)</span> with a function <span class="math notranslate nohighlight">\(h:\mathbb{R}\rightarrow [0,1]\)</span>. The logistic regression approach chooses</p>
<div class="math notranslate nohighlight">
\[
h(x) = \varphi \left( \vartheta^{\top} x \right) = \frac{1}{1+e^{-\vartheta^{\top} x}}
\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\varphi(x)=\frac{1}{1+e^{-x}}=\frac{1}{2}\left(1+\tanh\frac{x}{2}\right)\]</div>
<p>is the logistic function, also called the sigmoid function.</p>
<div style="text-align:center">
    <img src="https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg" alt="drawing" width="400"/>
</div>
<p>(Source: <a class="reference external" href="https://en.wikipedia.org/wiki/Sigmoid_function">Wikipedia</a>)</p>
<p>The advantage of this function lies in its many nice properties, such as its derivative:</p>
<div class="math notranslate nohighlight">
\[\varphi^{\prime} (x)=\frac{1}{1+e^{-x}} e^{-x}=\frac{1}{1+e^{-x}}\left(1-\frac{1}{1+e^{-x}}\right)=\varphi(x)(1-\varphi(x))\]</div>
<p>If we now want to apply the <em>Maximum Likelihood Estimation</em> approach, then we need to use our hypothesis to assign probabilities to the discrete events</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{cases}p(y=1 \mid x ; \vartheta)=h(x) &amp; \\ p(y=0 \mid x ; \vartheta)=1-h(x) &amp;
\end{cases}\end{split}\]</div>
<p>Our probability density function then becomes</p>
<div class="math notranslate nohighlight">
\[p(y \mid x ; \vartheta)=h^{y}(x)(1-h(x))^{1-y}\]</div>
<blockquote>
<div><p>This will look quite different for other types of labels, so be cautious in just copying this form of the pdf!</p>
</div></blockquote>
<p>With our pdf we can then again construct the likelihood function</p>
<div class="math notranslate nohighlight">
\[L(\vartheta) = p(y | x ; \vartheta) =\prod_{i=1}^{m} p\left(y^{(i)} \mid x^{(i)}, \vartheta\right)\]</div>
<p>Assuming the previously presumed classification buckets, and that the data is i.i.d.</p>
<div class="math notranslate nohighlight">
\[
L(\vartheta)=\prod_{i=1}^{m} h^{y^{(i)}}(x^{(i)})\left(1-h\left(x^{(i)}\right)\right)^{1-y^{(i)}}
\]</div>
<p>and then the log-likelihood decomposes to</p>
<div class="math notranslate nohighlight">
\[
l(\vartheta)=\log L(\vartheta)=\sum_{i=1}^{m}\left(y^{(i)} \log h\left(x^{(i)}\right)+\left(1-y^{(i)}\right) \log \left(1-h\left(x^{(i)}\right)\right)\right).
\]</div>
<p>Again we can find <span class="math notranslate nohighlight">\(\operatorname{argmax} l(\vartheta)\)</span> e.g. by gradient ascent (batch or stochastic):</p>
<div class="math notranslate nohighlight">
\[\vartheta_{j}^{(k+1)}=\vartheta_{j}^{(k)}+\left.\alpha \frac{\partial l(\vartheta)}{\partial \vartheta}\right|^{(k)}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\frac{\partial \ell(\vartheta)}{\partial \vartheta_j} &amp;=\left(y \frac{1}{h(x)}-(1-y) \frac{1}{1-h(x )}\right) \frac{\partial h(x)}{\partial \vartheta_j }\\
&amp;=\left(\frac{y-h(x)}{h(x)(1-h(x))}\right) h (x)(1-h (x)) x_j\\
&amp;=(y- h(x)) x_j
\end{align}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\Rightarrow \vartheta_{j}^{(k+1)}=\vartheta_{j}^{(k)}+\alpha \left( y^{(i)}-h(x^{(i)}) \right) x_j^{(i)}\]</div>
<p>which we can then solve with either batch gradient descent or stochastic gradient descent.</p>
<blockquote>
<div><p>The algorithm formally associated with the least squares method for logistic regression is slightly different!</p>
</div></blockquote>
<p>The alternative here is to utilize Newton’s method, which we have encountered before in numerical methods lectures. An application of Newton’s method then looks like the following:</p>
<div class="math notranslate nohighlight">
\[\vartheta_{j}^{(k+1)}=\vartheta_{j}^{(k)}\left(\left.\frac{\partial^{2} \ell}{\partial \vartheta_{i} \partial \vartheta_{j}}\right|^{(k)}\right)^{-1} \frac{\partial l}{\partial \vartheta_{j}}\]</div>
<p>Newton’s method converges quadratically, and our problem class is sufficiently smooth for Newton’s method to be applicable. The downside to this approach is that we have to compute the inverse Hessian matrix, which is an expensive computational operation.</p>
<p><strong>Exercise: Vanilla Indicator</strong></p>
<p>Using the “vanilla” indicator function instead of the sigmoid:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
g(x)= \begin{cases}1, &amp; x \geqslant 0 \\ 0, &amp; x&lt;0\end{cases}
\end{split}\]</div>
<p>derive the update functions for the gradient methods, as well as the Maximum Likelihood Estimator approach.</p>
</section>
<section id="exponential-family">
<h2>Exponential Family<a class="headerlink" href="#exponential-family" title="Permalink to this headline">#</a></h2>
<p>The exponential family of distributions is a large family of distributions with shared properties, some of which we have already encountered in other courses before. Prominent members of the exponential family include</p>
<ul class="simple">
<li><p>Bernoulli</p></li>
<li><p>Gaussian</p></li>
<li><p>Dirichlet</p></li>
<li><p>Gamma</p></li>
<li><p>Poisson</p></li>
<li><p>Beta</p></li>
</ul>
<p>At their core, members of the exponential family all fit the same general probability distribution form</p>
<div class="math notranslate nohighlight">
\[p(x|\eta) = h(x) \exp \left\{ \eta^{\top} t(x) - a(\eta) \right\}\]</div>
<p>where the individual components are</p>
<ul class="simple">
<li><p>Natural parameter <span class="math notranslate nohighlight">\(\eta\)</span></p></li>
<li><p>Sufficient statistic <span class="math notranslate nohighlight">\(t(x)\)</span></p></li>
<li><p>Probability support measure <span class="math notranslate nohighlight">\(h(x)\)</span></p></li>
<li><p>Log normalizer <span class="math notranslate nohighlight">\(a(\eta)\)</span> to guarantee that the probability density integrates to 1.</p></li>
</ul>
<blockquote>
<div><p>If you are unfamiliar with the concept of probability measures, then <span class="math notranslate nohighlight">\(h(x)\)</span> can safely be disregarded. Conceptually it describes the area in the probability space over which the probability distribution is defined.</p>
</div></blockquote>
<p><strong>Why is this family of distributions relevant to this course?</strong></p>
<blockquote>
<div><p>The exponential family has a direct connection to graphical models, which are a formalism favored by many people to visualize machine learning models, and the way individual components interact with each other. As such they are highly instructive, and at the same time foundational to many probabilistic approaches covered in this course.</p>
</div></blockquote>
<p>Let’s inspect the practical example of the Gaussian distribution to see how the theory translates into practice. Taking the probability density function which we have also previously worked with</p>
<div class="math notranslate nohighlight">
\[p(x|\mu, \sigma^{2}) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left\{ \frac{(x - \mu)^{2}}{2 \sigma^{2}} \right\}\]</div>
<p>We can then expand the square in the exponent of the Gaussian to isolate the individual components of the exponential family</p>
<div class="math notranslate nohighlight">
\[p(x|\mu, \sigma^{2}) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left\{ \frac{\mu}{\sigma^{2}}x - \frac{1}{2 \sigma^{2}}x^{2} - \frac{1}{2 \sigma^{2}} \mu^{2} - \log \sigma \right\}\]</div>
<p>Then the individual components of the Gaussian are</p>
<div class="math notranslate nohighlight">
\[\eta = \langle \frac{\mu}{\sigma^{2}}, - \frac{1}{2 \sigma^{2}} \rangle\]</div>
<div class="math notranslate nohighlight">
\[t(x) = \langle x, x^{2} \rangle\]</div>
<div class="math notranslate nohighlight">
\[a(\eta) = \frac{\mu^{2}}{2 \sigma^{2}} + \log \sigma\]</div>
<div class="math notranslate nohighlight">
\[h(x) = \frac{1}{\sqrt{2 \pi}}\]</div>
<p>For the sufficient statistics, we then need to derive the derivative of the log normalizer, i.e</p>
<div class="math notranslate nohighlight">
\[\frac{d}{d\eta}a(\eta) = \mathbb{E}\left[ t(X) \right]\]</div>
<p>Which yields</p>
<div class="math notranslate nohighlight">
\[\frac{da(\eta)}{d\eta_{1}} = \mu = \mathbb{E}[X] \]</div>
<div class="math notranslate nohighlight">
\[\frac{da(\eta)}{d\eta_{2}} = \mu = \mathbb{E}[X^{2}] \]</div>
<p><strong>Exercise: Exponential Family 1</strong></p>
<p>Show that the Dirichlet distribution is a member of the exponential family.</p>
<p><strong>Exercise: Exponential Family 2</strong></p>
<p>Show that the Bernoulli distribution is a member of the exponential family</p>
</section>
<section id="bayesian-inference">
<h2>Bayesian Inference<a class="headerlink" href="#bayesian-inference" title="Permalink to this headline">#</a></h2>
<p>The main ideals upon which Bayesian statistics is founded are</p>
<ul class="simple">
<li><p>Uncertainty over parameters -&gt; treatment as random variables</p></li>
<li><p>A probability over a parameter essentially expresses a degree of belief</p></li>
<li><p>Inference over parameters using rules of probability</p></li>
<li><p>We combine the prior knowledge and the observed data with Bayes’ theorem</p></li>
</ul>
<blockquote>
<div><p>Refresher - Bayes’ theorem is given by <span class="math notranslate nohighlight">\(\mathbb{P}(A|B) = \frac{\mathbb{P}(B|A)\mathbb{P}(A)}{\mathbb{P}(B)}\)</span></p>
</div></blockquote>
<p>So what we are interested in is the <strong>posterior</strong> distribution over our parameters, which can be found using Bayes’ theorem. While this may at first glance look straightforward, and holds for the <strong>unscaled posterior</strong> i.e the distribution which has not been normalized by dividing by <span class="math notranslate nohighlight">\(\mathbb{P}(B)\)</span>, obtaining the scaled posterior is much much harder due to the difficulty in computing the divisor <span class="math notranslate nohighlight">\(\mathbb{P}(B)\)</span>. To evaluate this divisor we draw on Monte Carlo sampling.</p>
<blockquote>
<div><p>What is a <em>scaled posterior</em>? A scaled posterior is a distribution whose integral over the entire distribution evaluates to 1.</p>
</div></blockquote>
<p>Taking Bayes’ theorem, and using the probability theorems in their conditional form we then obtain the following formula for the posterior density</p>
<div class="math notranslate nohighlight">
\[g(\theta | y) = \frac{g(\theta) \times f(y | \theta)}{\int g(\theta) \times f(y | \theta) d\theta}\]</div>
<p>If we now seek to compute the denominator, then we have to integrate</p>
<div class="math notranslate nohighlight">
\[\int f(y|\theta) g(\theta) d\theta.\]</div>
<section id="monte-carlo-sampling">
<h3>Monte Carlo Sampling<a class="headerlink" href="#monte-carlo-sampling" title="Permalink to this headline">#</a></h3>
<p>To approximate this quantity with Monte Carlo sampling techniques we then need to draw from the posterior <span class="math notranslate nohighlight">\(\int f(y|\theta) g(\theta) d\theta\)</span>. A process which given enough samples always converges to the true value of the denominator according to the <a class="reference external" href="http://www-star.st-and.ac.uk/~kw25/teaching/mcrt/MC_history_3.pdf">Monte Carlo theorem</a>.</p>
<p>Monte Carlo integration is a fundamental tool first developed by Physicists dealing with the solution of high-dimensional integrals. The main objective is solving integrals like</p>
<div class="math notranslate nohighlight">
\[E[h(\mathbf{x})]=\int h(\mathbf{x}) p(\mathbf{x}) d\mathbf{x}, \quad \mathbf{x}\in \mathbb{R}^d\]</div>
<p>with some function of interest <span class="math notranslate nohighlight">\(h\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> being a r.v.</p>
<p>The approach consists of the following three steps:</p>
<ol class="simple">
<li><p>Generate i.i.d. random samples <span class="math notranslate nohighlight">\(\mathbf{x}^{(i)}\in \mathbb{R}^d, \; i=1,2,...,N\)</span> from the density <span class="math notranslate nohighlight">\(p(\mathbf{x})\)</span>.</p></li>
<li><p>Evaluate <span class="math notranslate nohighlight">\(h^{(i)}=h(\mathbf{x}^{(i)}), \; \forall i\)</span>.</p></li>
<li><p>Approximate</p></li>
</ol>
<div class="math notranslate nohighlight">
\[E[h(\mathbf{x})]\approx \frac{1}{N}\sum_{i=1}^{N}h^{(i)}\]</div>
<hr class="docutils" />
<p>Bayesian approaches based on random Monte Carlo sampling from the posterior have a number of advantages for us:</p>
<ul class="simple">
<li><p>Given a large enough number of samples, we are not working with an approximation, but with an estimate which can be made as precise as desired (given the requisite computational budget)</p></li>
<li><p>Sensitivity analysis of the model becomes easier.</p></li>
</ul>
<section id="acceptance-rejection-sampling">
<h4>Acceptance-Rejection Sampling<a class="headerlink" href="#acceptance-rejection-sampling" title="Permalink to this headline">#</a></h4>
<p>Acceptance-rejection sampling draws its random samples directly from the target posterior distribution, as we only have access to the unscaled target distribution initially we will have to draw from the unscaled target. <em>The acceptance-rejection algorithm is specially made for this scenario.</em> The acceptance-rejection algorithm draws random samples from an easier-to-sample starting distribution and then successively reshapes its distribution by only selectively accepting candidate values into the final sample. For this approach to work the candidate distribution <span class="math notranslate nohighlight">\(g_{0}(\theta)\)</span> has to dominate the posterior distribution, i.e. there must exist an <span class="math notranslate nohighlight">\(M\)</span> s.t.</p>
<div class="math notranslate nohighlight">
\[M \times g_{0}(\theta) \geq g(\theta) f(y|\theta), \quad \forall \theta\]</div>
<p>Taking an example candidate density for an unscaled target as an example to show the “dominance” of the candidate distribution over the posterior distribution.</p>
<center>
<img src = "https://i.imgur.com/1xzbFI5.png" width = "450"></center>
<p>(Source, Bolstad <em>Understanding Computational Bayesian Statistics</em>)</p>
<p>To then apply acceptance-rejection sampling to the posterior distribution we can write out the algorithm as follows:</p>
<ol class="simple">
<li><p>Draw a random sample of size <span class="math notranslate nohighlight">\(N\)</span> from the candidate distribution <span class="math notranslate nohighlight">\(g_{0}(\theta)\)</span>.</p></li>
<li><p>Calculate the value of the unscaled target density at each random sample.</p></li>
<li><p>Calculate the candidate density at each random sample, and multiply by <span class="math notranslate nohighlight">\(M\)</span>.</p></li>
<li><p>Compute the weights for each random sample</p></li>
</ol>
<div class="math notranslate nohighlight">
\[ w_{i} = \frac{g(\theta_{i}) \times f(y_{1}, \ldots, y_{n}| \theta_{i})}{M \times g_{0}(\theta_{i})}\]</div>
<ol class="simple">
<li><p>Draw <span class="math notranslate nohighlight">\(N\)</span> samples from the <span class="math notranslate nohighlight">\(U(0, 1)\)</span> uniform distribution.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(u_{i} &lt; w_{i}\)</span> accept <span class="math notranslate nohighlight">\(\theta_{i}\)</span></p></li>
</ol>
</section>
<section id="sampling-importance-resampling-bayesian-bootstrap">
<h4>Sampling-Importance-Resampling / Bayesian Bootstrap<a class="headerlink" href="#sampling-importance-resampling-bayesian-bootstrap" title="Permalink to this headline">#</a></h4>
<p>The sampling-importance-resampling algorithm is a two-stage extension of the acceptance-rejection sampling which has an improved weight-calculation, but most importantly employs a <em>resampling</em> step. This resampling step resamples from the space of parameters. The weight is then calculated as</p>
<div class="math notranslate nohighlight">
\[w_{i} = \frac{\frac{g(\theta_{i})f(y_{1}, \ldots\ y_{n} | \theta_{i})}{g_{0}(\theta_{i})}}{\left( \sum_{i=1}^{N} \frac{g(\theta_{i})f(y_{1}, \ldots, y_{n}| \theta_{i})}{g_{0}(\theta_{i})} \right)} \]</div>
<p>The algorithm to sample from the posterior distribution is then:</p>
<ol class="simple">
<li><p>Draw <span class="math notranslate nohighlight">\(N\)</span> random samples <span class="math notranslate nohighlight">\(\theta_{i}\)</span> from the starting density <span class="math notranslate nohighlight">\(g_{0}(\theta)\)</span></p></li>
<li><p>Calculate the value of the unscaled target density at each random sample.</p></li>
<li><p>Calculate the starting density at each random sample, and multiply by <span class="math notranslate nohighlight">\(M\)</span>.</p></li>
<li><p>Calculate the ratio of the unscaled posterior to the starting distribution</p></li>
</ol>
<div class="math notranslate nohighlight">
\[r_{i} = \frac{g(\theta_{i})f(y_{1}, \ldots, y_{n}| \theta_{i})}{g_{0}(\theta_{i})}\]</div>
<ol class="simple">
<li><p>Calculate the importance weights</p></li>
</ol>
<div class="math notranslate nohighlight">
\[w_{i} = \frac{r_{i}}{\sum r_{i}}\]</div>
<ol class="simple">
<li><p>Draw <span class="math notranslate nohighlight">\(n \leq 0.1 \times N\)</span> random samples with the sampling probabilities given by the importance weights.</p></li>
</ol>
</section>
<section id="adaptive-rejection-sampling">
<h4>Adaptive Rejection Sampling<a class="headerlink" href="#adaptive-rejection-sampling" title="Permalink to this headline">#</a></h4>
<p>If we are unable to find a candidate/starting distribution, which dominates the unscaled posterior distribution immediately, then we have to rely on <em>adaptive rejection sampling</em>.</p>
<blockquote>
<div><p>This approach only works for a log-concave posterior!</p>
</div></blockquote>
<p>See below for an example of a log-concave distribution.</p>
<center>
<img src = "https://i.imgur.com/8j4zCVo.png" width = "550"></center>
<p>(Source: Bolstad, <em>Understanding Computational Bayesian Statistics</em>)</p>
<p>Using the tangent method our algorithm then takes the following form:</p>
<ol class="simple">
<li><p>Construct an upper bound from piecewise exponential functions, which dominate the log-concave unscaled posterior</p></li>
<li><p>With the envelope giving us the initial candidate density we draw <span class="math notranslate nohighlight">\(N\)</span> random samples</p></li>
<li><p>Rejection sampling, see the preceding two subsections for details.</p></li>
<li><p>If rejected, add another exponential piece which is tangent to the target density.</p></li>
</ol>
<p>As all three presented sampling approaches have their limitations, practitioners tend to rely more on Markov chain Monte Carlo methods such as Gibbs sampling, and Metropolis-Hastings.</p>
</section>
<section id="markov-chain-monte-carlo">
<h4>Markov Chain Monte Carlo<a class="headerlink" href="#markov-chain-monte-carlo" title="Permalink to this headline">#</a></h4>
<p>The idea of Markov Chain Monte Carlo (MCMC) is to construct an ergodic Markov chain of samples <span class="math notranslate nohighlight">\(\{\theta^0, \theta^1, ...,\theta^N\}\)</span> distributed according to the posterior distribution <span class="math notranslate nohighlight">\(g(\theta|y)\)</span>. This chain evolves according to a transition kernel given by <span class="math notranslate nohighlight">\(q(x_{next}|x_{current})\)</span>. Let’s look at one of the most popular MCMC algorithms: Metropolis Hastings</p>
<p><strong>Metropolis-Hastings</strong></p>
<p>The general Metropolis-Hastings prescribes a rule which guarantees that the constructed chain is representative of the target distribution <span class="math notranslate nohighlight">\(g(\theta|y)\)</span>. This is done by following the algorithm:</p>
<ol class="simple">
<li><p>Start at an initial point <span class="math notranslate nohighlight">\(\theta_{current} = \theta^0\)</span>.</p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(\theta' \sim q(\theta_{next}|\theta_{current})\)</span></p></li>
<li><p>Compute
$<span class="math notranslate nohighlight">\(\alpha = min \left\{ 1, \frac{g(\theta'|y) q(\theta_{current}|\theta')}{g(\theta_{current}|y) q(\theta'|\theta_{current})} \right\}\)</span>$</p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(u\sim \text{Uniform}(0,1)\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(\alpha &gt; u\)</span>, then <span class="math notranslate nohighlight">\(\theta_{current} = \theta'\)</span>, else <span class="math notranslate nohighlight">\(\theta_{current} = \theta_{current}\)</span></p></li>
<li><p>Repeat <span class="math notranslate nohighlight">\(N\)</span> times from step 1.</p></li>
</ol>
<p>A special choice of <span class="math notranslate nohighlight">\(q(\cdot | \cdot)\)</span> is for example the normal distribution <span class="math notranslate nohighlight">\(\mathcal{N}(\cdot | \theta_{current}, \sigma^2)\)</span>, which results in the so-called Random Walk Metropolis algorithm. Other special cases include the Metropolis-Adjusted Langevin Algorithm (MALA), as well as the Hamiltonian Monte Carlo (HMC) algorithm. For more information, refer to <a class="reference external" href="https://link.springer.com/book/10.1007/978-1-4757-4145-2">Monte Carlo Statistical Methods</a> by Rober &amp; Casella.</p>
<hr class="docutils" />
<p>In summary:</p>
<ul class="simple">
<li><p>The unscaled posterior <span class="math notranslate nohighlight">\(g(\theta|y) \propto g(\theta)f(y|\theta)\)</span> contains the <em>shape information</em> of the posterior</p></li>
<li><p>For the true posterior, the unscaled posterior needs to be divided by an integral over the whole parameter space.</p></li>
<li><p>Integral has to be evaluated numerically for which we rely on the just presented Monte Carlo sampling techniques.</p></li>
</ul>
</section>
</section>
<section id="id1">
<h3>Bayesian Inference<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>In the Bayesian framework, everything centers around the posterior distribution and our ability to relate our previous knowledge with newly gained evidence to the next stage of our belief (of a probability distribution). With the posterior being our entire inference about the parameters given the data there exist multiple inference approaches with their roots in frequentist statistics.</p>
<section id="bayesian-point-estimation">
<h4>Bayesian Point Estimation<a class="headerlink" href="#bayesian-point-estimation" title="Permalink to this headline">#</a></h4>
<p>Bayesian point estimation chooses a single value to represent the entire posterior distribution. Potential choices here are locations like the posterior mean, and posterior median. For the posterior mean squared error, the posterior mean is then the first moment of the posterior distribution</p>
<div class="math notranslate nohighlight">
\[PMS(\hat{\theta}) = \int (\theta - \hat{\theta})^{2} g(\theta | y_{1}, \ldots, y_{n})d\theta\]</div>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \int_{-\infty}^{\infty} \theta g(\theta | y_{1}, \ldots, y_{n})d \theta\]</div>
<center>
<img src = "https://i.imgur.com/C5WdqqR.png" width = "450"></center>
<p>and for the posterior median <span class="math notranslate nohighlight">\(\tilde{\theta}\)</span></p>
<div class="math notranslate nohighlight">
\[PMAD(\hat{\theta}) = \int |\theta - \hat{\theta}| g(\theta| y_{1}, \ldots, y_{n})d\theta\]</div>
<div class="math notranslate nohighlight">
\[.5 = \int_{-\infty}^{\tilde{\theta}} g(\theta | y_{1}, \ldots, y_{n}) d\theta\]</div>
<center>
<img src = "https://i.imgur.com/u2b81gQ.png" width = "450"></center>
</section>
<section id="bayesian-interval-estimation">
<h4>Bayesian Interval Estimation<a class="headerlink" href="#bayesian-interval-estimation" title="Permalink to this headline">#</a></h4>
<p>Another type of Bayesian inference is the one in which we seek to find an interval that, with a pre-determined probability, contains the true value. In Bayesian statistics, these are called credible intervals. Finding the interval with equal tail areas to both sides <span class="math notranslate nohighlight">\((\theta_{l}, \theta_{u})\)</span>, and which has the probability to contain the true value of the parameter, i.e.</p>
<div class="math notranslate nohighlight">
\[\int_{-\infty}^{\theta_{l}} g(\theta | y_{1}, \ldots, y_{n}) d\theta = \frac{\alpha}{2}\]</div>
<div class="math notranslate nohighlight">
\[\int_{\theta_{u}}^{\infty} g(\theta | y_{1}, \ldots, y_{n}) d\theta = \frac{\alpha}{2}\]</div>
<p>which we then only need to solve. A visual example of such a scenario is in the following picture:</p>
<center>
<img src = "https://i.imgur.com/ofkfuF0.png" width = "450"></center>
<p>(Source: Bolstad, <em>Understanding Computational Bayesian Statistics</em>)</p>
<!---
#### Maximum A Posteriori Estimation (MAP)

Blubba blub
--->
</section>
<section id="predictive-distribution-of-a-new-observation">
<h4>Predictive Distribution of a New Observation<a class="headerlink" href="#predictive-distribution-of-a-new-observation" title="Permalink to this headline">#</a></h4>
<p>If we obtain a new observation, then we can compute the updated predictive distribution by combining the conditional distribution of the new observation, and conditioning it on the previous observations. Then we only need to integrate the parameter out of the joint posterior</p>
<div class="math notranslate nohighlight">
\[f(y_{n+1}|y_{1}, \ldots, y_{n}) \propto \int g(\theta) \times f(y_{n+1}| \theta) \times \ldots \times f(y_{1}|\theta) d\theta\]</div>
<div class="math notranslate nohighlight">
\[\propto \int f(y_{n+1}|\theta)g(\theta|y_{1}, \ldots, y_{n}) d\theta\]</div>
<p>and marginalize it out.</p>
</section>
<section id="bayesian-inference-from-a-posterior-random-sample">
<h4>Bayesian Inference from a Posterior Random Sample<a class="headerlink" href="#bayesian-inference-from-a-posterior-random-sample" title="Permalink to this headline">#</a></h4>
<p>When we only have a random sample from the posterior instead of the approximation, we are still able to apply the same techniques, but just apply them to the posterior sample.</p>
<p>With our rudimentary approximations of the denominator by sampling from the posterior. This only constitutes an approximation, but given the sampling budget, this approximation can be made as accurate as desired. In summary Bayesian inference can be condensed to the following main take-home knowledge:</p>
<ul class="simple">
<li><p>The posterior distribution is the current summary of beliefs about the parameter in the Bayesian framework.</p></li>
<li><p>Bayesian inference is then performed using the probabilities calculated from the posterior distribution of the parameter.</p>
<ul>
<li><p>To get an approximation of the scaling factor for the posterior we have to utilize sampling-based Monte Carlo techniques to approximate the requisite integral.</p></li>
</ul>
</li>
</ul>
</section>
</section>
</section>
<section id="bayesian-approaches-to-regression">
<h2>Bayesian Approaches to Regression<a class="headerlink" href="#bayesian-approaches-to-regression" title="Permalink to this headline">#</a></h2>
<p>If we are faced with the scenario of having very little data, then we ideally seek to quantify the uncertainty of our model and preserve the predictive utility of our machine learning model. The right approach to this is to extend Linear Regression, and Logistic Regression with the just presented Bayesian Approach utilizing Bayesian Inference.</p>
<section id="bayesian-logistic-regression">
<h3>Bayesian Logistic Regression<a class="headerlink" href="#bayesian-logistic-regression" title="Permalink to this headline">#</a></h3>
<p>If we now want to capture the uncertainty over our predictions in our logistic regression, then we have to resort to the Bayesian approach. To make the Bayesian approach work for logistic regression, we have to apply something called the <em>Laplace Approximation</em> in which we approximate the posterior using a Gaussian</p>
<div class="math notranslate nohighlight">
\[p(\omega | \mathcal{D}) \approx \mathcal{N}({\bf{\omega}}| {\bf{\hat{\omega}}}, {\bf{H}}^{-1})\]</div>
<p>where <span class="math notranslate nohighlight">\(H^{-1}\)</span> is the inverse of the Hessian, <span class="math notranslate nohighlight">\(\omega\)</span> corresponds to the learned parameters <span class="math notranslate nohighlight">\(\vartheta\)</span>, and <span class="math notranslate nohighlight">\(\hat{\omega}\)</span> is the MLE of <span class="math notranslate nohighlight">\(\vartheta\)</span>. There exist many different modes representing viable solutions for this problem when we seek to optimize it.</p>
<center>
<img src = "https://i.imgur.com/1nGR1Ju.png" width = "450"></center>
<p>(Source, <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>)</p>
<p>Using a Gaussian prior centered at the origin, we can then multiply our prior with the likelihood to obtain the unnormalized posterior. Which yields us the posterior predictive distribution</p>
<div class="math notranslate nohighlight">
\[p(y|x, \mathcal{D}) = \int p(y | x, \omega) p(\omega | \mathcal{D})) d\omega\]</div>
<p>To now compute the uncertainty in our predictions we use a Gaussian prior, and then perform a <em>Monte Carlo Approximation</em> of the integral using <span class="math notranslate nohighlight">\(S\)</span> samples from the posterior <span class="math notranslate nohighlight">\(\omega_s \sim p(\omega|\mathcal{D})\)</span></p>
<div class="math notranslate nohighlight">
\[p(y=1 | x, \mathcal{D}) = \frac{1}{S} \sum_{s=1}^{S} \sigma \left( \omega_{s}^{\top} x \right)\]</div>
<p>Looking at a larger visual example of Bayesian Logistic Regression applied.</p>
<center>
<img src = "https://i.imgur.com/oBsUrVi.jpg" width = "600"></center>
<p>(Source: <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>)</p>
</section>
<section id="bayesian-linear-regression">
<h3>Bayesian Linear Regression<a class="headerlink" href="#bayesian-linear-regression" title="Permalink to this headline">#</a></h3>
<p>To now introduce the Bayesian approach to linear regression we have to assume that we already know the variance <span class="math notranslate nohighlight">\(\sigma^{2}\)</span>, so the posterior which we actually compute at that point is</p>
<div class="math notranslate nohighlight">
\[p(\omega | \mathcal{D}, \sigma^{2})\]</div>
<p>If we then take a Gaussian distribution as our prior distribution <span class="math notranslate nohighlight">\(p(\omega)\)</span></p>
<div class="math notranslate nohighlight">
\[p(\omega) = \mathcal{N}(\omega | \breve{\omega}, \breve{\Sigma})\]</div>
<p>Then we can write down the likelihood as a Multivariate-Normal distribution.</p>
<div class="math notranslate nohighlight">
\[p(\mathcal{D} | \omega, \sigma^{2}) = \prod_{n=1}^{N}p(y_{n}|{\bf{\omega^{\top}}}{\bf{x}}, \sigma^{2}) = \mathcal{N}({\bf{y}} | {\bf{X} \bf{\omega}}, \sigma^{2} {\bf{I}}_{N})\]</div>
<p>The posterior can then be analytically derived using Bayes’ rule for Gaussians (see <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>, eq. 3.37)</p>
<div class="math notranslate nohighlight">
\[p({\bf{\omega}} | {\bf{X}}, {\bf{y}}, \sigma^{2}) \propto \mathcal{N}(\omega | \breve{\omega}, \breve{\Sigma}) \mathcal{N}({\bf{y}} | {\bf{X} \bf{\omega}}, \sigma^{2} {\bf{I}}_{N}) = \mathcal{N}({\bf{\omega}} | {\bf{\hat{\omega}}}, {\bf{\hat{\Sigma}}}) \]</div>
<div class="math notranslate nohighlight">
\[{\bf{\hat{\omega}}} \equiv {\bf{\hat{\Sigma}}} \left( {\bf{\breve{\Sigma}}}^{-1} {\bf{\breve{\omega}}} + \frac{1}{\sigma^{2}} {\bf{X^{\top} y}}  \right)\]</div>
<div class="math notranslate nohighlight">
\[{\bf{\hat{\Sigma}}} \equiv \left( {\bf{\breve{\Sigma}}}^{-1} + \frac{1}{\sigma^{2}} {\bf{X^{\top} X}} \right)^{-1}\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\omega}\)</span> is the posterior mean, and <span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span> is the posterior covariance. A good visual example of this is the sequential Bayesian inference on a linear regression model:</p>
<center>
<img src = "https://i.imgur.com/87em7Vz.png" width = "550"></center>
<p>(Source, <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>)</p>
</section>
</section>
<section id="bayesian-machine-learning">
<h2>Bayesian Machine Learning<a class="headerlink" href="#bayesian-machine-learning" title="Permalink to this headline">#</a></h2>
<p>Let’s consider the setup we have encountered so far in which we have labels <span class="math notranslate nohighlight">\(x\)</span>, hyperparameters <span class="math notranslate nohighlight">\(\theta\)</span>, and seek to predict labels <span class="math notranslate nohighlight">\(y\)</span>. Probabilistically expressed this amounts to <span class="math notranslate nohighlight">\(p(y|x, \theta)\)</span>. Then the posterior is defined as <span class="math notranslate nohighlight">\(p(\theta| \mathcal{D})\)</span>, where <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is our labeled dataset</p>
<div class="math notranslate nohighlight">
\[\mathcal{D} = \left\{ (x_{n}, y_{n}):n=1:N \right\}\]</div>
<p>Applying the previously discussed Bayesian approaches to these problems, and the respective model parameters, are called <strong>Bayesian Machine Learning</strong>.</p>
<p>While we lose computational efficiency at first glance, as we have to perform a sampling-based inference procedure, what we gain is a principled approach to discuss uncertainties within our model. This can help us most especially when we move in the <em>small-data limit</em>, where we can not realistically expect our model to converge. See e.g. below a Bayesian logistic regression example in which the posterior distribution is visualized.</p>
<center>
<img src = "https://i.imgur.com/AfikBRy.png" width = "550"></center>
<p>(Source: <a class="reference external" href="https://github.com/probml/pml-book">Murphy</a>)</p>
</section>
<section id="further-references">
<h2>Further References<a class="headerlink" href="#further-references" title="Permalink to this headline">#</a></h2>
<p><strong>Linear &amp; Logistic Regression</strong></p>
<ul class="simple">
<li><p>Machine Learning Basics <a class="reference external" href="https://www.youtube.com/watch?v=73RL3WPPFE0&amp;list=PLQ8Y4kIIbzy_OaXv86lfbQwPHSomk2o2e&amp;index=2">video</a> and <a class="reference external" href="https://niessner.github.io/I2DL/slides/2.Linear.pdf">slides</a> from the “Introduction to Deep Learning” course for Informatics students at TUM.</p></li>
<li><p><a class="reference external" href="https://betanalpha.github.io/assets/case_studies/underdetermined_linear_regression.html">What happens if a linear regression is underdetermined i.e. we have fewer observations than parameters?</a></p></li>
</ul>
<p><strong>Bayesian Methods</strong>
There exist a wide number of references to the herein presented Bayesian approach, most famously introductory treatment of Probabilistic Programming frameworks, which utilize the herein presented modeling approach to obtain posteriors over programs.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://pyro.ai/examples/intro_long.html">Introduction to Pyro</a></p></li>
<li><p><a class="reference external" href="https://m-clark.github.io/bayesian-basics/example.html#posterior-predictive">A Practical Example with Stan</a></p></li>
</ul>
<p>In addition, there exists highly curated didactic material from Michel Betancourt:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://betanalpha.github.io/assets/case_studies/sampling.html">Sampling</a>: Section 3, 4, and 5</p></li>
<li><p><a class="reference external" href="https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html">Towards a Principled Bayesian Workflow</a></p></li>
<li><p><a class="reference external" href="https://betanalpha.github.io/assets/case_studies/markov_chain_monte_carlo.html">Markov Chain Monte Carlo</a>: Section 1, 2, and 3</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lecture"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="motivation.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introduction</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="cc-2-optimization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Core Content 2: Optimization</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By N. Adams, L. Paehler, A. Toshev<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>