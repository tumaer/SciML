

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>10. Convolutional Neural Networks &#8212; Introduction to Scientific Machine Learning for Engineers</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lecture/cnn';</script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="11. Recurrent Models" href="rnn.html" />
    <link rel="prev" title="9. Multilayer Perceptron" href="mlp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../about.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Introduction to Scientific Machine Learning for Engineers - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Introduction to Scientific Machine Learning for Engineers - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../about.html">
                    About this Lecture
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lecture</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="linear.html">1. Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="gmm.html">2. Gaussian Mixture Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="bayes.html">3. Bayesian methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="optimization.html">4. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="tricks.html">5. Tricks of Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="svm.html">6. Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="gp.html">7. Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="gradients.html">8. Gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="mlp.html">9. Multilayer Perceptron</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">10. Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="rnn.html">11. Recurrent Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ae.html">12. Encoder-Decoder Models</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercise</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercise/linear.html">1. Linear and Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/bayes.html">2. Bayesian Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/optimization.html">3. Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/svm.html">4. Support Vector Machines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/gp.html">5. Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/cnn.html">6. Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exercise/rnn.html">7. Recurrent Neural Networks</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Miscellaneous</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../admin.html">Admin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../books.html">Books</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preliminary_knowledge.html">Preliminary Knowledge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software.html">Software Infrastructure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../practical_exam.html">Practical Exam WS22/23</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tumaer/SciML" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tumaer/SciML/issues/new?title=Issue%20on%20page%20%2Flecture/cnn.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/lecture/cnn.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Convolutional Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-mlp">10.1. Limitations of MLP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutions">10.2. Convolutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filters">10.2.1. Filters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensions-of-a-convolution">10.3. Dimensions of a Convolution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding">10.3.1. Padding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride">10.3.2. Stride</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dilation">10.3.3. Dilation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling">10.4. Pooling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#channels">10.4.1. Channels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modern-cnns">10.5. Modern CNNs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alexnet-2012">10.5.1. AlexNet (2012)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vggnet-2014">10.5.2. VGGNet (2014)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resnet-2016">10.5.3. ResNet (2016)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#u-net-2015">10.5.4. U-Net (2015)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convnext-2022-and-convnextv2-2023">10.5.5. ConvNext (2022) and ConvNextv2 (2023)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-references">10.6. Further References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="convolutional-neural-networks">
<h1><span class="section-number">10. </span>Convolutional Neural Networks<a class="headerlink" href="#convolutional-neural-networks" title="Permalink to this heading">#</a></h1>
<section id="limitations-of-mlp">
<h2><span class="section-number">10.1. </span>Limitations of MLP<a class="headerlink" href="#limitations-of-mlp" title="Permalink to this heading">#</a></h2>
<p>In the previous subsection, we saw how the Multilayer Perceptron (a.k.a. Feedforward Neural Network, or Fully Connected Neural Network) generalizes linear models by stacking many linear models and placing nonlinear activation functions in between. Also, by the Universal Approximation Theorem, we saw that such a construction is enough to learn any function. But is an MLP always practical?</p>
<p>In this subsection, we will concentrate on working with images. Imagine that we have an image with 1000x1000 pixels and 3 RGB channels. If we take an MLP with one hidden layer of size 1000, this means that the weight matrix from input to layer 1 would have 3 billion parameters to map all 3M inputs to each of the 1k neurons in layer 1. This number is too large for most modern consumer hardware and thus such a network could not be easily trained or deployed.</p>
<p>MLPs are in a sense the most brute-force deep learning technique. By directly connecting all inputs to all next-layer neurons, we don’t introduce any bias and this is at least currently just too hard for image data.</p>
<p>The core idea of Convolutional Neural Networks is to introduce weight sharing, i.e. different regions of the image are treated with the same weights.</p>
</section>
<section id="convolutions">
<h2><span class="section-number">10.2. </span>Convolutions<a class="headerlink" href="#convolutions" title="Permalink to this heading">#</a></h2>
<div style="text-align:center">
    <img src="https://i.imgur.com/1AJ3d98.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://betterexplained.com/articles/intuitive-convolution/">Intuitive Guide to Convolution</a>)</p>
<p>Applying a convolution filter (a.k.a. kernel) to a 2D image looks might look like this.</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/ygH2Go6.png" alt="drawing" width="350"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html">d2l.ai</a>)</p>
<section id="filters">
<h3><span class="section-number">10.2.1. </span>Filters<a class="headerlink" href="#filters" title="Permalink to this heading">#</a></h3>
<p>In image processing, specific (convolution) kernels have a well-understood meaning. Examples include:</p>
<ul class="simple">
<li><p>Edge detection</p></li>
<li><p>Sharpening</p></li>
<li><p>Mean blur</p></li>
<li><p>Gaussian blur</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/PKCBAVh.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_(image_processing)">Wikipedia</a></p>
<p>The kernels is modern deep learnig lead to features like these:</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/xvljdrQ.png" alt="drawing" width="600"/>
</div>
<p>(Image credit: Yann LeCun 2016, adapted from <a class="reference external" href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler &amp; Fergus 2013</a></p>
</section>
</section>
<section id="dimensions-of-a-convolution">
<h2><span class="section-number">10.3. </span>Dimensions of a Convolution<a class="headerlink" href="#dimensions-of-a-convolution" title="Permalink to this heading">#</a></h2>
<p>If you got excited about CNNs and open the documentation to one of the most popular ML libraries PyTorch, in the corresponding <code class="docutils literal notranslate"><span class="pre">torch.nn.Conv2d</span></code> section you will find the following equations.</p>
<p>Input: <span class="math notranslate nohighlight">\((C_{in}, H_{in}, W_{in})\)</span>
Output: <span class="math notranslate nohighlight">\((C_{out}, H_{out}, W_{out})\)</span></p>
<p>Here, <span class="math notranslate nohighlight">\(C\)</span> is the number of channels, e.g. 3 for an RGB input image, <span class="math notranslate nohighlight">\(H\)</span> is the height, and <span class="math notranslate nohighlight">\(W\)</span> is the width of an image.</p>
<div class="math notranslate nohighlight">
\[H_{out}= \left\lfloor \frac{H_{in} + 2\cdot \text{padding}[0] - \text{dilation}[0] \cdot (\text{kernel_size}[0]-1) - 1}{\text{stride}[0]} + 1 \right\rfloor\]</div>
<div class="math notranslate nohighlight">
\[W_{out}=\left\lfloor \frac{W_{in} + 2\cdot \text{padding}[1] - \text{dilation}[1] \cdot (\text{kernel_size}[1]-1) - 1}{\text{stride}[1]} + 1 \right\rfloor\]</div>
<p>With <span class="math notranslate nohighlight">\(\lfloor \cdot \rfloor\)</span> we denote the floor operator. Let’s look at what each of these new terms means.</p>
<section id="padding">
<h3><span class="section-number">10.3.1. </span>Padding<a class="headerlink" href="#padding" title="Permalink to this heading">#</a></h3>
<p>Applying a convolution directly to an image would result in an image of a smaller height and width. To counteract that, we pad the image height and width for example with zeros. With proper padding, one can stack hundreds of convolution layers without changing the width and height. The padding can be different along the width and height dimensions; we denote width and height padding with <span class="math notranslate nohighlight">\(\text{padding}[0]\)</span> and <span class="math notranslate nohighlight">\(\text{padding}[1]\)</span>. <span class="math notranslate nohighlight">\(\text{padding}=0\)</span> is the original convolution.</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/swEdDMq.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html">d2l.ai</a>)</p>
<p>Another reason for padding is to use the corner pixels equally often as other pixels. The image below shows how often a pixel would be used by a convolutoin kernel of size 1x1, 2x2, and 3x3 without padding.</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/T0NkS8w.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html">d2l.ai</a>)</p>
<p>Two commonly used terms regarding padding are the following:</p>
<ul class="simple">
<li><p><em>valid</em> convolution: no padding</p></li>
<li><p><em>same</em> convolution: <span class="math notranslate nohighlight">\(H_{in}=H_{out}, \; W_{in}=W_{out}\)</span>.</p></li>
</ul>
</section>
<section id="stride">
<h3><span class="section-number">10.3.2. </span>Stride<a class="headerlink" href="#stride" title="Permalink to this heading">#</a></h3>
<p>If we want to reduce the overlap between kernels and also reduce <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(H\)</span> of the outputs, we can introduce a <span class="math notranslate nohighlight">\(\text{stride}&gt;1\)</span> variable. <span class="math notranslate nohighlight">\(\text{stride}=1\)</span> results in the original convolution. In the image below we see <span class="math notranslate nohighlight">\(\text{stride}=\text{Array}([2, 3])\)</span>.</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/Ays8u2j.png" alt="drawing" width="400"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html">d2l.ai</a>)</p>
</section>
<section id="dilation">
<h3><span class="section-number">10.3.3. </span>Dilation<a class="headerlink" href="#dilation" title="Permalink to this heading">#</a></h3>
<p>This is a more exotic operation, which works well for detecting large-scale features. <span class="math notranslate nohighlight">\(\text{dilation}=1\)</span> corresponds to the original convolution.</p>
<p><img alt="Optimization" src="../_images/dilation.gif" /></p>
<p>(Source: <a class="github reference external" href="https://github.com/vdumoulin/conv_arithmetic">vdumoulin/conv_arithmetic</a>)</p>
</section>
</section>
<section id="pooling">
<h2><span class="section-number">10.4. </span>Pooling<a class="headerlink" href="#pooling" title="Permalink to this heading">#</a></h2>
<p>You can think of a convolution filter as a feature extraction transformation similar to the basis expansion with general linear models. Here, the basis itself is learned via CNN layers.</p>
<p>If we are interested in image classification, we don’t just want to transform the input features, but also extract / select the relevant information. This is done by pooling layers in between convolution layers. Pooling layers don’t have learnable parameters and the inevitable reduce dimensionality. Typical examples are:</p>
<ul class="simple">
<li><p>max / min pooling</p></li>
<li><p>mean pooling (averaging)</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/c1s6T2F.png" alt="drawing" width="300"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/pooling.html">d2l.ai</a>)</p>
<section id="channels">
<h3><span class="section-number">10.4.1. </span>Channels<a class="headerlink" href="#channels" title="Permalink to this heading">#</a></h3>
<p>Each convolution kernel operates on all <span class="math notranslate nohighlight">\(C_{in}\)</span> input channels, resulting in a number of parameters per kernel <span class="math notranslate nohighlight">\(C_{in} \cdot \text{kernel_size}[0] \cdot \text{kernel_size}[1]\)</span>. Having <span class="math notranslate nohighlight">\(C_{out}\)</span> number of kernels results in a number of parameters per convolution layer of</p>
<p><span class="math notranslate nohighlight">\(C_{in} \cdot C_{out} \cdot \text{kernel_size}[0] \cdot \text{kernel_size}[1]\)</span></p>
<div style="text-align:center">
    <img src="https://i.imgur.com/JMVifDx.png" alt="drawing" width="550"/>
</div>
<p>(Source: <a class="reference external" href="https://d2l.ai/chapter_convolutional-neural-networks/channels.html">d2l.ai</a>)</p>
</section>
</section>
<section id="modern-cnns">
<h2><span class="section-number">10.5. </span>Modern CNNs<a class="headerlink" href="#modern-cnns" title="Permalink to this heading">#</a></h2>
<p>A typical CNN would look something like the following.</p>
<div style="text-align:center">
    <img src="https://i.imgur.com/YQLkWG9.png" alt="drawing" width="550"/>
</div>
<p>(Source: <a class="reference external" href="http://cs231n.stanford.edu/slides/2021/lecture_5.pdf">cs231n, CNN lecture</a>)</p>
<p>We now head to a historical overview of the recent trends since the beginning of the deep learning revolution with AlexNet in 2012.</p>
<section id="alexnet-2012">
<h3><span class="section-number">10.5.1. </span><a class="reference external" href="https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">AlexNet</a> (2012)<a class="headerlink" href="#alexnet-2012" title="Permalink to this heading">#</a></h3>
<p>Characteristics:</p>
<ul class="simple">
<li><p>rather larger filters with 11x11</p></li>
<li><p>first big successes of ReLU</p></li>
<li><p>60M parameters</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/ylA5l5O.png" alt="drawing" width="600"/>
</div>
<p>(Source: <a class="reference external" href="https://niessner.github.io/I2DL/slides/10.CNN-2.pdf">I2DL, TUM</a>)</p>
</section>
<section id="vggnet-2014">
<h3><span class="section-number">10.5.2. </span><a class="reference external" href="https://arxiv.org/abs/1409.1556">VGGNet</a> (2014)<a class="headerlink" href="#vggnet-2014" title="Permalink to this heading">#</a></h3>
<p>Characteristics:</p>
<ul class="simple">
<li><p>much simpler structure</p></li>
<li><p>3x3 convolutions, stride 1, same convolutions</p></li>
<li><p>2x2 max pooling</p></li>
<li><p>deeper</p></li>
<li><p>138M parameters</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/Pxekgh6.png" alt="drawing" width="600"/>
</div>
<p>(Source: <a class="reference external" href="https://niessner.github.io/I2DL/slides/10.CNN-2.pdf">I2DL, TUM</a>)</p>
</section>
<section id="resnet-2016">
<h3><span class="section-number">10.5.3. </span><a class="reference external" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf">ResNet</a> (2016)<a class="headerlink" href="#resnet-2016" title="Permalink to this heading">#</a></h3>
<p>Charasteristics:</p>
<ul class="simple">
<li><p>allows for very deep networks by introducing skip connections</p></li>
<li><p>this mitigates the vanishing and exploiding gradients problem</p></li>
<li><p>ResNet-152 (with 152 layers) has 60M parameters</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/6gwMcYz.png" alt="drawing" width="700"/>
</div>
<p>(Source: <a class="reference external" href="https://niessner.github.io/I2DL/slides/10.CNN-2.pdf">I2DL, TUM</a>)</p>
</section>
<section id="u-net-2015">
<h3><span class="section-number">10.5.4. </span><a class="reference external" href="https://arxiv.org/abs/1505.04597">U-Net</a> (2015)<a class="headerlink" href="#u-net-2015" title="Permalink to this heading">#</a></h3>
<p>Characteristics:</p>
<ul class="simple">
<li><p>for image segmentation</p></li>
<li><p>skip connections</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/kk2asgp.png" alt="drawing" width="600"/>
</div>
<p>(Source: <a class="reference external" href="https://niessner.github.io/I2DL/slides/10.CNN-2.pdf">I2DL, TUM</a>)</p>
</section>
<section id="convnext-2022-and-convnextv2-2023">
<h3><span class="section-number">10.5.5. </span><a class="reference external" href="https://arxiv.org/abs/2201.03545">ConvNext</a> (2022) and <a class="reference external" href="https://arxiv.org/pdf/2301.00808.pdf">ConvNextv2</a> (2023)<a class="headerlink" href="#convnext-2022-and-convnextv2-2023" title="Permalink to this heading">#</a></h3>
<p>Characteristics:</p>
<ul class="simple">
<li><p>since the <a class="reference external" href="https://arxiv.org/abs/2010.11929">Vision Transformer</a> many people started believing that the inductive bias of translational invariance encoded in a convolution is too restrictive for images classification. However, the release of the <a class="reference external" href="https://arxiv.org/abs/2201.03545">ConvNext</a> model (“A ConvNet for the 2020s”, Liu et al. 2022) points in the direction that many innovations have been made on improving transformers, e.g. the GELU activations, and if we simply apply some of them to CNNs, we also end up with state-of-the-art results.</p></li>
</ul>
<div style="text-align:center">
    <img src="https://i.imgur.com/CQ0hNVZ.png" alt="drawing" width="500"/>
</div>
<p>(Source: <a class="reference external" href="https://arxiv.org/abs/2201.03545">ConvNext</a>)</p>
<p>The successor paper of ConvNext -&gt; ConvNextv2 just came out one week ago!</p>
</section>
</section>
<section id="further-references">
<h2><span class="section-number">10.6. </span>Further References<a class="headerlink" href="#further-references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://www.deeplearningbook.org/">Deep Learning</a>, Chapters 6; Goodgellow, Bengio, Courville; 2016</p></li>
<li><p><a class="reference external" href="https://d2l.ai/index.html">d2l</a>, Chapter 6 and 7; Zhang et al.; 2022</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./lecture"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="mlp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">9. </span>Multilayer Perceptron</p>
      </div>
    </a>
    <a class="right-next"
       href="rnn.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Recurrent Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limitations-of-mlp">10.1. Limitations of MLP</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#convolutions">10.2. Convolutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filters">10.2.1. Filters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dimensions-of-a-convolution">10.3. Dimensions of a Convolution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#padding">10.3.1. Padding</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stride">10.3.2. Stride</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dilation">10.3.3. Dilation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pooling">10.4. Pooling</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#channels">10.4.1. Channels</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modern-cnns">10.5. Modern CNNs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#alexnet-2012">10.5.1. AlexNet (2012)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vggnet-2014">10.5.2. VGGNet (2014)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#resnet-2016">10.5.3. ResNet (2016)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#u-net-2015">10.5.4. U-Net (2015)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convnext-2022-and-convnextv2-2023">10.5.5. ConvNext (2022) and ConvNextv2 (2023)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#further-references">10.6. Further References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By N. Adams, L. Paehler, A. Toshev
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022,2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>